{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating data for spell Bee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Imports\n",
    "import nltk\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of all words in english dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234377"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_vocab = set(w.lower() for w in nltk.corpus.words.words())\n",
    "len(english_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all words with occurences of letter \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131270"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_vocab_without_s = [word for word in english_vocab if \"s\" not in word]\n",
    "len(english_vocab_without_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out all possible pangrams using 7 unique letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pangram = [word for word in english_vocab if len(set(word)) == 7]\n",
    "seen_letter = set()\n",
    "pangram = {word: list(set(list(word))) for word in english_vocab_without_s if len(set(word)) == 7}\n",
    "\n",
    "# pangram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store it in pangrams.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pangram.json\", 'w') as file:\n",
    "    json.dump(pangram, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign weights to each letter based on their occurences in pangram(50%) and overall wordlist(50%)\n",
    "\n",
    "Weights range from (0-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "alphabets_lowercase = list(string.ascii_lowercase)\n",
    "alphabets_lowercase.remove('s')\n",
    "# alphabets_lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabets_weight_pangram = {}\n",
    "\n",
    "for word in pangram:\n",
    "    for letter in alphabets_lowercase :\n",
    "        if letter in alphabets_weight_pangram and letter in word:\n",
    "            alphabets_weight_pangram[letter] +=1\n",
    "        elif letter in word:\n",
    "            alphabets_weight_pangram[letter] = 1\n",
    "# alphabets_weight_pangram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabets_weight_non_pangram = {}\n",
    "\n",
    "for word in english_vocab_without_s:\n",
    "    for letter in alphabets_lowercase :\n",
    "        if letter in alphabets_weight_non_pangram and letter in word:\n",
    "            alphabets_weight_non_pangram[letter] +=1\n",
    "        elif letter in word:\n",
    "            alphabets_weight_non_pangram[letter] = 1\n",
    "\n",
    "# alphabets_weight_non_pangram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet_weight = {}\n",
    "for letter, weight in alphabets_weight_pangram.items():\n",
    "    # alphabet_weight (40% from pangram weight, 60% from non pangram weight)\n",
    "    alphabet_weight[letter] = ((weight/len(pangram)*.4) + (alphabets_weight_non_pangram[letter]/len(english_vocab_without_s)*.6))*10\n",
    "    alphabet_weight[letter] = round(alphabet_weight[letter], 4)\n",
    "# alphabet_weight\n",
    "\n",
    "# if alphabet_weight > 1 => can occur in inner\n",
    "# if alphabet_weight >  0.3  => can occur in outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"letter_weights.json\", 'w') as file:\n",
    "    json.dump(alphabet_weight, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 6.3357,\n",
       " 'b': 1.6973,\n",
       " 'e': 6.6969,\n",
       " 'f': 1.0179,\n",
       " 'l': 4.5849,\n",
       " 'r': 5.5877,\n",
       " 't': 4.9821,\n",
       " 'd': 2.8959,\n",
       " 'i': 5.9059,\n",
       " 'n': 5.3235,\n",
       " 'o': 4.9991,\n",
       " 'p': 2.4795,\n",
       " 'c': 3.6686,\n",
       " 'u': 2.7966,\n",
       " 'x': 0.3307,\n",
       " 'g': 2.0215,\n",
       " 'y': 2.0357,\n",
       " 'm': 2.5371,\n",
       " 'h': 2.194,\n",
       " 'z': 0.4235,\n",
       " 'v': 0.857,\n",
       " 'k': 0.742,\n",
       " 'w': 0.6525,\n",
       " 'q': 0.1486,\n",
       " 'j': 0.1477}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('unactuated', {'a', 'c', 'd', 'e', 'n', 't', 'u'}, 't')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "def choose_letters_for_spellbee():\n",
    "    vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "    inner = None\n",
    "    vowel_present_in_choice = False\n",
    "\n",
    "    while not vowel_present_in_choice:\n",
    "        choice = random.choice(list(pangram.keys()))\n",
    "        for vowel in vowels:\n",
    "            if vowel in choice:\n",
    "                vowel_present_in_choice = True\n",
    "\n",
    "    while inner is None:\n",
    "        inner_choice = random.choice(list(choice))\n",
    "        if alphabet_weight[inner_choice] > float(1.0):\n",
    "            inner = inner_choice\n",
    "            return choice, set(choice), inner\n",
    "w, l, i = choose_letters_for_spellbee()\n",
    "# list(pangram.values())[0]\n",
    "w, l, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "['refund', 'hippomancy', 'pontificality', 'woodprint', 'plug', 'banbury', 'pianologue', 'preinvolve', 'amiidae', 'allophyle', 'crake', 'monomeric', 'fluoryl', 'noncortical', 'dihydrol']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_15_words(letters: list, inner: str) -> bool:\n",
    "    \"\"\" \"\"\"\n",
    "    count_of_words = 0\n",
    "    words = []\n",
    "    for word in english_vocab_without_s:\n",
    "        if inner not in word:\n",
    "            continue\n",
    "        for letter in word:\n",
    "            if letter not in letters:\n",
    "                continue\n",
    "        count_of_words += 1\n",
    "        words.append(word)\n",
    "\n",
    "        if count_of_words >= 15:\n",
    "            print(count_of_words)\n",
    "            print(words)\n",
    "            return True\n",
    "    return False\n",
    "check_15_words(l, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'b'}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sort_set(set1: set) -> set:\n",
    "    \"\"\" \"\"\"\n",
    "    list1 = list(set1)\n",
    "    list1.sort()\n",
    "    # print(list1)\n",
    "    return set(list1)\n",
    "\n",
    "a = set(['b', 'a'])\n",
    "sort_set(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u'] ['e', 'r', 'l', 'b', 'm', 'c']\n",
      "{'u', 'c', 'l', 'e', 'r', 'm', 'b'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_my_pangram(inner: list, outer: list) -> bool:\n",
    "    \"\"\" \"\"\"\n",
    "    letters = inner + outer\n",
    "    for word in pangram:\n",
    "        letters = set(letters)\n",
    "        word = set(word)\n",
    "        if sort_set(letters) == sort_set(word):\n",
    "            print(word)\n",
    "            return True\n",
    "    return False\n",
    "        \n",
    "        \n",
    "inner, outer = choose_letters_for_spellbee()\n",
    "find_my_pangram(inner, outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
